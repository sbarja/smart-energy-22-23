{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/top_ML.png\" alt=\"Drawing\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# EJERCICIO\n",
    "# Aprendizaje no supervisado: Clustering.\n",
    "\n",
    "## *Clustering de consumidores*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el aprendizaje no supervisado, la tarea clásica es el **análisis de clusters** (grupos) en el que se encuentran patrones o grupos ocultos en los datos. La mayoría de las veces las tareas de aprendizaje no supervisado tienen una *solución abierta*, por lo que hay que interpretar los resultados y comprobar si tienen sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** En este ejemplo se utilizan datos que contienen información acerca del consumo eléctrico de un grupo de consumidores eléctricos. El objetivo es encontrar el número óptimo de clusters para agrupar los diferentes patrones de consumo diarios. El resultado se utilizará para fines comerciales y estratégicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes de empezar:\n",
    "\n",
    "* En el archivo **clustering-consumos.xlsx** se encuentra el conjunto de datos de entrada de este ejemplo (atributos). \n",
    "* **NO** existen las etiquetas en el Aprendizaje **NO Supervisado**. \n",
    "\n",
    "\n",
    "<img src=\"Figures/no-supervisado.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importar librerías y datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Librería de visualización de datos\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Seleccionamos las columnas que necesitamos\n",
    "df_consumos = pd.read_excel('Data\\S7-Clustering-consumos.xlsx')\n",
    "df_consumos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Comprender los datos**\n",
    "\n",
    "Es necesario visualizar y comprender los datos con los que vamos a trabajar, así como conocer sus características. \n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b> ¿Cuántos datos hay?¿Cuántos atributos hay en los datos? </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión de los datos de entrada (filas x columnas)\n",
    "df_consumos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos como es la apariencia de los datos\n",
    "df_consumos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumos.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Ponemos como índice el identificador del contador inteligente (CUP) </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pongo como índice el número de CUP \n",
    "df_consumos.set_index('CUPs', inplace = True)\n",
    "df_consumos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Comprobamos si existe algún dato categórico que haya que transformar </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumos.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> ¿Falta algún dato? </b>\n",
    "</div>\n",
    "\n",
    "Se comprueba si falta algún dato, y de ser así, se realiza el recuento de celdas vacías en cada atributo. En este caso, no falta ningún dato en el conjunto de datos de entrada (no existen valores *Nan*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumos.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos **interpolación** para imputar los valores que faltan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de datos con pandas\n",
    "df_consumos.interpolate(method='polynomial', order=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que se han imputado los valores correctamente\n",
    "df_consumos.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Resumen estadístico del conjunto de datos de entrada: </b>\n",
    "</div>\n",
    "\n",
    "La estadística descriptiva recolecta y analiza el conjunto de datos de entrada con el objetivo de describir las características y comportamientos de este conjunto mediante las siguientes medidas resumen: número total de observaciones (count), media (mean), desviación estándar (std), valor mínimo (min), valor máximo (max) y los valores de los diferentes cuartiles (25%, 50%, 75%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la naturaleza de los datos con datos estadísticos descriptivos\n",
    "df_consumos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Visualizar los datos**\n",
    "\n",
    "Una manera visual de entender los datos de entrada. \n",
    "1. Histograma\n",
    "2. Curva de densidad\n",
    "3. Boxplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Histograma </b>\n",
    "</div>\n",
    "\n",
    "\n",
    "Respresentación gráfica de cada uno de los atributos en forma de barras, donde la superficie de la barra es proporcional a la frecuencia de los valores representados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograma = df_consumos.hist(xlabelsize=10, ylabelsize=10, bins=100, figsize=(18, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Gráfico de densidades </b>\n",
    "</div>\n",
    "\n",
    "Visualiza la distribución de los datos. Es una variable del histograma, pero elimina el ruido, por lo que son mejores para determinar la forma de distribución de un atributo. Lo spicos del gráfico de densidad ayudan a mostrar dónde los valores se concentran más. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = df_consumos.plot(kind='kde', legend=True, layout=(1, 1), figsize=(18, 12),\n",
    "                        fontsize=20, stacked=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Boxplots </b>\n",
    "</div>\n",
    "\n",
    "\n",
    "El boxplot (diagrama de caja) nos permite identificar los valores atípicos y comparar distribuciones. Además, se conoce como se distribuyen el 50% de los valores (dentro de la caja).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boxplot = df_consumos.plot(kind='box', legend=True, layout=(1, 1), figsize=(18, 12),\n",
    "                        fontsize=16, stacked=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *4. Preparar los datos*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b> Graficamos los datos de consumo </b>\n",
    "</div>\n",
    "\n",
    "El gráfico muestra el consumo horario de un grupo de consumidores durante un día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumo horario\n",
    "df_consumos.T.plot(figsize=(18, 8), title='Consumo diario', legend=False, color='blue', alpha=0.05, \n",
    "                   fontsize=15, xlim=[0,23], ylabel='Energía Consumida [kWh]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b> Escalar los datos </b>\n",
    "</div>\n",
    "\n",
    "\n",
    "<img src=\"Figures\\scaling.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Como ya se ha comentado, tanto **MinMaxScaler()** como **StandardScaler()** se utilizan comúnmente para escalar datos antes de aplicar el algoritmo de clustering. Sin embargo, la elección entre ellos depende de las características específicas de los datos y requisitos del análisis.\n",
    "\n",
    "* **MinMaxScaler()** escala los datos a un rango fijo, generalmente entre 0 y 1. Esto puede ser útil si los datos tienen un rango limitado y se desea preservar la relación entre los valores de diferentes features/características. Sin embargo, puede no ser adecuado para datos con valores atípicos/outliers, ya que pueden tener un impacto desproporcionado en la escala.\n",
    "\n",
    "* **StandardScaler()** escala los datos para tener una media cero y una varianza unitaria, lo que lo hace útil para datos que están distribuidos de manera normal o tienen una distribución similar. Puede ser más robusto a los valores atípicos que MinMaxScaler(), pero puede que no preserve la relación entre los valores de diferentes características.\n",
    "\n",
    "Se escalan los datos utilizando el método de *MinMaxScaler()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = df_consumos.values.copy()\n",
    "X_scale = pd.DataFrame(scaler.fit_transform(X))\n",
    "X_scale.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Guardamos el scaler de los datos de entreno para utilizarlo luego </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardamos el scaler en un archivo para utilizarlo luego\n",
    "joblib.dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Construcción del modelo de aprendizaje NO supervisado: Clustering de consumos utilizando K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agrupan los datos utilizando el algoritmo [K-Means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "\n",
    "El algoritmo K-means necesita que se le indique el número de clústers en que se quieren agrupar los datos. Se ejecuta el algoritmo para varios clusters y luego se comparan los resultados utilizando el método Elbow, que indicará el número óptimo de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "elbow_method = []\n",
    "\n",
    "# Evalúo el algoritmo K-means para un rango de [2,10] clústers \n",
    "n_cluster_list = range(2,15)\n",
    "print(list(n_cluster_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo saber el número óptimo de clusters? Con el método de Elbow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Aplicamos el método de Elbow como métrica para selecionar un número óptimo de clusters. \n",
    "</div>\n",
    "    \n",
    "Se utiliza el [Método de Elbow] para ayudarnos a elegir el número óptimo de clusters. \n",
    "\n",
    "* Este método utiliza los valores de la inercia obtenidos tras aplicar el K-means a diferente número de Clusters (desde 1 a N Clusters), siendo la inercia la suma de las distancias al cuadrado de cada objeto del Cluster a su centroide.\n",
    "* Para hacer uso de este método partimos del cálculo de la distorsión promedio de cada clúster, esto es la distancia de cada elemento con su centroide correspondiente.\n",
    "* Buscamos la parte de la gráfica donde la línea es menos suave o cambia abruptamente lo que forma un “codo”.\n",
    "\n",
    "[Método de Elbow]: https://jarroba.com/seleccion-del-numero-optimo-clusters/\n",
    "\n",
    "    \n",
    "**EJEMPLO:**\n",
    "\n",
    "<img src=\"Figures\\elbow-method.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Método de Elbow. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iteración para evaluar K-means para diferentes números de clusters (n_clusters)\n",
    "for n_cluster in n_cluster_list:\n",
    "    kmeans = KMeans(n_clusters=n_cluster, random_state=0)\n",
    "    cluster_found = kmeans.fit_predict(X_scale)\n",
    "    elbow_method.append(kmeans.inertia_) \n",
    "\n",
    "\n",
    "# Gráfica del método de Elbow\n",
    "plt.plot(n_cluster_list, elbow_method, 'bx-')\n",
    "plt.xlabel('Número de centroides')\n",
    "plt.ylabel('Within-Cluster Sum of Square')\n",
    "plt.title('Método Elbow para número óptimo de clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El número óptimo de clusters es...¿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Entrenar el algorithmo de clustering K-Means con k clusters \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Entreno el K-means para k=X, visto el resultado del método Elbow\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "cluster_found = kmeans.fit_predict(X_scale)\n",
    "cluster_found_sr = pd.Series(cluster_found, name='cluster')\n",
    "\n",
    "# Creo un multindex del tipo: (fecha,cluster al que pertenece el día)\n",
    "df_consumos = df_consumos.set_index(cluster_found_sr, append=True)\n",
    "\n",
    "#Guardamos los clusters en un excel\n",
    "df_consumos.to_excel('Data/S7-resultados-clusters.xlsx')\n",
    "\n",
    "df_consumos.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Mostrar los resultados de este Clustering de consumos \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14,5))\n",
    "color_list = ['blue', 'green', 'red', 'orange']\n",
    "cluster_values = sorted(df_consumos.index.get_level_values('cluster').unique())\n",
    "\n",
    "for cluster, color in zip(cluster_values, color_list):\n",
    "    # ploteo todas las lineas de cada cluster\n",
    "    df_consumos.xs(cluster, level=1).T.plot(ax=ax, legend=False, alpha=0.05, color=color)\n",
    "    # ploteo la línea con el valor de la mediana de cada cluster\n",
    "    df_consumos.xs(cluster, level=1).median().plot(ax=ax, color=color, legend=False, alpha=1, ls='--')\n",
    "\n",
    "ax.set_ylabel('Potencia media horaria [kW]')\n",
    "ax.set_xlabel('Horas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Extra) Validar los resultados con Dimensionality Reduction (PCA)\n",
    "\n",
    "*  Explicación de PCA visualmente. https://setosa.io/ev/principal-component-analysis/\n",
    "\n",
    "\n",
    "* Principal Component Analysis (PCA) es un método estadístico que permite simplificar la complejidad de espacios muestrales con muchas dimensiones a la vez que conserva su información. Se reducen las \"features\" de 24 a 2. \n",
    "* Una forma de validar los resultados del algoritmo clustering es mediante técnicas de dimensionality reduction. Hay que tener en cuenta es que el PCA no sabe nada de los grupos encontrados por K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.colors\n",
    "\n",
    "pca = PCA(n_components=2)  \n",
    "results_pca = pca.fit_transform(X_scale)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(cluster_values, color_list)\n",
    "\n",
    "plt.scatter(results_pca[:, 0], results_pca[:, 1],\n",
    "            c = df_consumos.index.get_level_values('cluster'),\n",
    "            cmap=cmap,\n",
    "            alpha=0.4,\n",
    "            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Guarda el modelo entrenado de K-means para utilizarlo más tarde y no tener que entrenarlo de nuevo. </b>\n",
    "</div>\n",
    "\n",
    "\n",
    "<img src=\"Figures\\save-ml-model.png\" alt=\"Drawing\" style=\"width: 1200px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(kmeans, 'kmeans_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar un modelo de K-Means guardado y predecir clusters a partir de nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Carga el modelo entrenado de K-means y el scaler con los datos de entreno. </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo el modelo de k-means\n",
    "kmeans = joblib.load('kmeans_model.joblib')\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo el scaler del archivo\n",
    "scaler = joblib.load('scaler.joblib')\n",
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Cargo los nuevos datos de entrada </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "new_data = pd.read_excel('Data/S7-clustering-consumos-new-data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pongo como índice el número de CUP \n",
    "new_data.set_index('CUPs', inplace = True)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Debo de escalar estos nuevos datos de entrada, ya que en el entrenamiento han sido escalados. </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_data_scaled = pd.DataFrame(scaler.transform(new_data))\n",
    "#new_data_scaled.columns = new_data.columns\n",
    "new_data_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade scikit-learn threadpoolctl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Realizo predicciones de cluster de los datos nuevos, utilizando el modelo K-Means entrenado anteriormente. </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_labels = kmeans.predict(new_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizo el resultado del clustering de datos nuevos\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_found_new_data_sr = pd.Series(predicted_labels, name='cluster')\n",
    "cluster_found_new_data_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un multindex del tipo: (fecha,cluster al que pertenece el día)\n",
    "new_data = new_data.set_index(cluster_found_new_data_sr, append=True)\n",
    "new_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> RECORDATORIO: Grafico otra vez los consumos de entreno obtenidos, para luego comparar. </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14,5))\n",
    "color_list = ['blue', 'green', 'red', 'orange']\n",
    "cluster_values = sorted(df_consumos.index.get_level_values('cluster').unique())\n",
    "\n",
    "for cluster, color in zip(cluster_values, color_list):\n",
    "    # ploteo todas las lineas de cada cluster\n",
    "    df_consumos.xs(cluster, level=1).T.plot(ax=ax, legend=False, alpha=0.05, color=color)\n",
    "    # ploteo la línea con el valor de la mediana de cada cluster\n",
    "    df_consumos.xs(cluster, level=1).median().plot(ax=ax, color=color, legend=False, alpha=1, ls='--')\n",
    "    print(\"Color:\", color, \"se asocia al clúster \", cluster)\n",
    "\n",
    "ax.set_ylabel('Potencia media horaria [kW]')\n",
    "ax.set_xlabel('Horas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Grafico los nuevos datos </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumo horario\n",
    "new_data.T.plot(figsize=(14, 5), title='Consumo diario', legend=False, color='blue', alpha=0.5, \n",
    "                   fontsize=15, xlim=[0,23], ylabel='Energía Consumida [kWh]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Unifico las dos gráficas y coloreo acorde al cluster asociado </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14,5))\n",
    "color_list = ['blue', 'green', 'red', 'orange']\n",
    "cluster_values = sorted(df_consumos.index.get_level_values('cluster').unique())\n",
    "\n",
    "print(\"CLUSTERS entrenamiento\")\n",
    "for cluster, color in zip(cluster_values, color_list):\n",
    "    # ploteo todas las lineas de cada cluster\n",
    "    df_consumos.xs(cluster, level=1).T.plot(ax=ax, legend=False, alpha=0.05, color=color)\n",
    "    # ploteo la línea con el valor de la mediana de cada cluster\n",
    "    df_consumos.xs(cluster, level=1).median().plot(ax=ax, color=color, legend=False, alpha=1, ls='--')\n",
    "    print(\"Color:\", color, \"se asocia al clúster \", cluster)\n",
    "\n",
    "#new data\n",
    "print(\"CLUSTERS nuevos datos de entrada\")\n",
    "color_list = ['blue', 'red', 'orange']\n",
    "cluster_values = sorted(new_data.index.get_level_values('cluster').unique())\n",
    "for cluster, color in zip(cluster_values, color_list):\n",
    "    # ploteo todas las lineas de cada cluster\n",
    "    new_data.xs(cluster, level=1).T.plot(ax=ax, legend=False, alpha=0.40, color=color)\n",
    "    # ploteo la línea con el valor de la mediana de cada cluster\n",
    "    #new_data.xs(cluster, level=1).median().plot(ax=ax, color=color, legend=False, alpha=1, ls='--')   \n",
    "    print(\"Color:\", color, \"se asocia al clúster \", cluster)\n",
    "\n",
    "    \n",
    "ax.set_ylabel('Potencia media horaria [kW]')\n",
    "ax.set_xlabel('Horas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Muestro solo los consumos del nuevo dataset, coloreados según su cluster asociado según K-Means </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14,5))\n",
    "print(\"CLUSTERS nuevos datos de entrada\")\n",
    "color_list = ['blue', 'red', 'orange']\n",
    "cluster_values = sorted(new_data.index.get_level_values('cluster').unique())\n",
    "for cluster, color in zip(cluster_values, color_list):\n",
    "    # ploteo todas las lineas de cada cluster\n",
    "    new_data.xs(cluster, level=1).T.plot(ax=ax, legend=False, alpha=0.40, color=color)\n",
    "    # ploteo la línea con el valor de la mediana de cada cluster\n",
    "    #new_data.xs(cluster, level=1).median().plot(ax=ax, color=color, legend=False, alpha=1, ls='--')   \n",
    "    print(\"Color:\", color, \"se asocia al clúster \", cluster)\n",
    "\n",
    "    \n",
    "ax.set_ylabel('Potencia media horaria [kW]')\n",
    "ax.set_xlabel('Horas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
